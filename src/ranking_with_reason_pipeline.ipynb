{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.schema import Document\n",
    "import spacy\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove unwanted characters, extra spaces, and normalize whitespace\n",
    "    cleaned_text = text.replace('\\n', ' ').replace('\\x0c', '').strip()\n",
    "    return ' '.join(cleaned_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_prep import load_data, read_docx\n",
    "job_code = 'JPC-55662'\n",
    "job_desc_path = f'../data/{job_code}/{job_code} Job Description.docx'\n",
    "job_description = clean_text(read_docx(job_desc_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_prep import load_data, read_docx\n",
    "job_code = 'JPC-55662'\n",
    "resumes_path = f'../data/{job_code}/resume_data'\n",
    "resumes = load_data(resumes_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skills(resume_txt):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    skills = \"jz_skill_patterns.jsonl\"\n",
    "\n",
    "    ruler = nlp.add_pipe(\"entity_ruler\", before = \"ner\")\n",
    "    ruler.from_disk(skills)\n",
    "    doc = nlp(resume_txt)\n",
    "\n",
    "    resume_skill_list = set()\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"SKILL\":\n",
    "            resume_skill_list.add(ent.text.lower())\n",
    "\n",
    "    return resume_skill_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_skills = get_skills(job_description)\n",
    "job_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_skill_weights(llm, job_description, job_skills):\n",
    "    prompt_template=ChatPromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        I need your help to analyze the following job description and extract the skills mentioned. For each skill, please assign a weightage between 0 and 1, where 1 indicates the skill is most critical for the job, and 0 indicates it is least important.\n",
    "        Skills should mostly include tech stacks and tools but can also include concepts and procedures that need to be known.\n",
    "        Here is the job description:\n",
    "        \"{job_description}\"\n",
    "\n",
    "        Here is a list of skills identified by a spaCy model. Use this as a reference. Add to this list or remove unapplicable skills. The final list should not exceed 10 skills:\n",
    "        {job_skills}\n",
    "\n",
    "        Skills should not be too specific. If you identify related skills that can be logically combined into a broader category, group them together and provide a single weightage for the broader category. Ensure that the weightages reflect the importance of each skill or category based on the job description. Make sure the skills are commonly found in resumes.\n",
    "\n",
    "        Please provide the extracted skills along with their corresponding weightages in the following format:\n",
    "        - Skill: [skill_name], Weightage: [weightage]\n",
    "\n",
    "        Make sure to rank the skills based on their importance to the job.\n",
    "\n",
    "        \"\"\"\n",
    "    )\n",
    "    prompt = prompt_template.invoke({\"job_description\": job_description, \"job_skills\": job_skills})\n",
    "    result = llm.invoke(prompt)\n",
    "    print(result.content)\n",
    "    return result.content\n",
    "    \n",
    "def parse_resume_skill_weights(input_string):\n",
    "    pattern = r\"Skill:\\s*(.*?),\\s*Weightage:\\s*(\\d+\\.\\d+)\"\n",
    "\n",
    "    # Find all matches in the input text\n",
    "    matches = re.findall(pattern, input_string)\n",
    "\n",
    "    # Convert matches to a DataFrame\n",
    "    df = pd.DataFrame(matches, columns=['skill', 'weightage'])\n",
    "\n",
    "    # Convert Weightage to numeric type\n",
    "    df['weightage'] = pd.to_numeric(df['weightage'])\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key=os.environ['GROQ_API_KEY']\n",
    "llm=ChatGroq(groq_api_key=groq_api_key,\n",
    "         model_name=\"mixtral-8x7b-32768\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_llm(llm, retriever, skill):\n",
    "    prompt_template=ChatPromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "    You are a job recruiter evaluating a candidate's resume. Based on the resume content provided, \n",
    "    please evaluate the candidate's proficiency in {skill} on a scale of 1 to 5, where:\n",
    "    1 - No proficiency or mention\n",
    "    2 - Basic understanding \n",
    "    3 - Intermediate proficiency \n",
    "    4 - Proficient\n",
    "    5 - Expert-level proficiency\n",
    "\n",
    "    Do not use information that is not related to {skill}. \n",
    "    Resume Content: {context}\n",
    "\n",
    "    Score for {skill}: \n",
    "\n",
    "    Please provide it in the following format:\n",
    "    score: (integer from 1-5)\n",
    "    reason: (short explanation for your score)\n",
    "    \"\"\"\n",
    "    )\n",
    "    relevant_docs = retriever.invoke(skill)\n",
    "    context = \" \".join([doc.page_content for doc in relevant_docs])\n",
    "    prompt = prompt_template.invoke({\"context\": context, \"skill\": skill})\n",
    "    result = llm.invoke(prompt)\n",
    "    print(result.content)\n",
    "    return result.content\n",
    "\n",
    "def parse_score_reason(input_string):\n",
    "    if input_string == None:\n",
    "        return None, None\n",
    "    score_match = re.search(r'score:\\s*(\\d+)', input_string)\n",
    "    reason_match = re.search(r'reason:\\s*(.*)', input_string, re.DOTALL)\n",
    "    \n",
    "    # Extract and return values\n",
    "    score = int(score_match.group(1)) if score_match else None\n",
    "    reason = reason_match.group(1).strip() if reason_match else None\n",
    "    \n",
    "    return score, reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_string = get_job_skill_weights(llm, job_description, job_skills)\n",
    "skill_df = parse_resume_skill_weights(temp_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_scores= []\n",
    "for i in range(resumes.shape[0]):\n",
    "    print(\"----------------\", resumes['id'].iloc[i])\n",
    "    single_document = Document(page_content=clean_text(resumes['body'].iloc[i]))\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=50)\n",
    "    docs = text_splitter.split_documents([single_document])\n",
    "    \n",
    "    #loading the embedding model from huggingface\n",
    "    embedding_model_name = \"BAAI/bge-small-en-v1.5\"\n",
    "    # model_kwargs = {\"device\": \"cuda\"}\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=embedding_model_name,\n",
    "    # model_kwargs=model_kwargs\n",
    "    )\n",
    "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "    \n",
    "    retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 3, \"score_threshold\": 0.3})\n",
    "    \n",
    "\n",
    "    \n",
    "    scores = []\n",
    "    reasons = []\n",
    "\n",
    "    # Loop through each skill, call the function, and parse the result\n",
    "    for skill in skill_df['skill']:\n",
    "        input_string = prompt_llm(llm, retriever, skill)\n",
    "        score, reason = parse_score_reason(input_string)\n",
    "        scores.append(score)\n",
    "        reasons.append(reason)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    data = {'skill': list(skill_df['skill']), 'score': scores, 'reason': reasons}\n",
    "    df = pd.DataFrame(data)\n",
    "    merged_df = pd.merge(df, skill_df, how='inner')\n",
    "    merged_df['weighted_Score'] = merged_df['score'] * merged_df['weightage']\n",
    "\n",
    "    # Calculate the weighted sum\n",
    "    final_score = merged_df['weighted_Score'].sum()\n",
    "    resume_scores.append(final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes['final_score'] = resume_scores\n",
    "resumes.sort_values(by='final_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e4_LangChain_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
